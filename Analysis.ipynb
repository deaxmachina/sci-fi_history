{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77844e45-1f8c-4ee5-a2b2-d95fa20e6752",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dea/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import json\n",
    "import os \n",
    "import pickle\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "from spacy.matcher import Matcher\n",
    "import textacy\n",
    "from textacy import extract\n",
    "from textacy import preprocessing\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#sns.set_style('whitegrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4801228f-503d-4782-9960-541e035dd582",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dea/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3444: DtypeWarning: Columns (8) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./pg_catalog.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fc11843-3712-4929-ace9-0d9832843355",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d2d9a2f-8979-4cb9-aafc-6cc4a581786b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Authors', 'Title', 'Subjects'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58947794-5cca-4501-94c2-c6c5557e2ccd",
   "metadata": {},
   "source": [
    "### Author born and died years\n",
    "Extract the range, birth and death years of the first author. We will only consider books which have an author and they have years. We will use these as a proxy for years when their books were written, as we don't have this metadata. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dc6b507-cc61-499a-8dde-1b7f6b114ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_years(x):\n",
    "    years = re.findall(r'\\d+(?:-\\d+)+', x)\n",
    "    if len(years) > 0:\n",
    "        return years[0]\n",
    "    else:\n",
    "        return 'no year'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20bf0624-0837-451b-a0a2-496358290510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_year_born(x):\n",
    "    if x == 'no year':\n",
    "        return '9999'\n",
    "    else:\n",
    "        return x.split('-')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc41fd3c-c75e-48c4-aab0-d1357ee7751c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_year_died(x):\n",
    "    if x == 'no year':\n",
    "        return '9999'\n",
    "    else:\n",
    "        return x.split('-')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "382153df-e716-4a74-a923-4a55d7593523",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q3/7wmphwj9575b1g06mj1hl7gr0000gn/T/ipykernel_50625/2676397994.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['first_author_years_range'] = df['Authors'].apply(lambda x : extract_years(x))\n",
      "/var/folders/q3/7wmphwj9575b1g06mj1hl7gr0000gn/T/ipykernel_50625/2676397994.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['first_author_born'] = df['first_author_years_range'].apply(lambda x : extract_year_born(x)).astype(int)\n",
      "/var/folders/q3/7wmphwj9575b1g06mj1hl7gr0000gn/T/ipykernel_50625/2676397994.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['first_author_died'] = df['first_author_years_range'].apply(lambda x : extract_year_died(x)).astype(int)\n"
     ]
    }
   ],
   "source": [
    "# Add columns with the range, birth and death years\n",
    "df['first_author_years_range'] = df['Authors'].apply(lambda x : extract_years(x))\n",
    "df['first_author_born'] = df['first_author_years_range'].apply(lambda x : extract_year_born(x)).astype(int)\n",
    "df['first_author_died'] = df['first_author_years_range'].apply(lambda x : extract_year_died(x)).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41d5812-9594-4936-ade6-056865fc1fa8",
   "metadata": {},
   "source": [
    "### Filtering the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4823d8cd-38f1-4800-a81d-af3c17a9ce38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the authors for whom we don't have birth years \n",
    "df = df[df['first_author_born'] != 9999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34b4b156-b564-44f5-8833-8987e964210c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only need books that have science fiction in the list of subjects\n",
    "df = df[df['Subjects'].str.contains('Science fiction')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be055e80-30a0-4a2d-a640-41297b7229ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only need 'text' books\n",
    "df = df[df['Type'] == 'Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cb61649-4f7c-4dd3-9281-e731475a01a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only english books\n",
    "df = df[df['Language'] == 'en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "665cabd7-fdd4-46a8-8967-962c9e7ced18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take authors born within such a range that they reasonably wrote their books about 100 years ago\n",
    "df = df[(df['first_author_born'] > 1850) & (df['first_author_born'] < 1940)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151444c5-0618-466b-93d3-d9d463f1b05f",
   "metadata": {},
   "source": [
    "## Get the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2640d90-9bc4-484d-aa07-acd6e63f8754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of the texts ids that we want \n",
    "text_ids = df['Text#'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dec36e8b-aa0a-4a66-b948-8df2eef6e7ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2316"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ded3c32-655c-49c9-89d8-9c93332237bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_books = []\n",
    "def get_texts(list_ids):\n",
    "    texts = {}\n",
    "    for book_id in list_ids:\n",
    "        # try: \n",
    "        #     with open('./gutenberg_clean/{}.txt'.format(book_id)) as f:\n",
    "        #         text = f.read()\n",
    "        #         texts.append(text)\n",
    "        # except:\n",
    "        #     missing_books.append(book_id)\n",
    "        try: \n",
    "            with open('./gutenberg_clean/{}.txt'.format(book_id)) as f:\n",
    "                text = f.read()\n",
    "                texts[book_id] = text\n",
    "        except:\n",
    "            try: \n",
    "                with open('./gutenberg_clean/pg{}.txt'.format(book_id)) as f:\n",
    "                    text = f.read()\n",
    "                    texts[book_id] = text\n",
    "            except:\n",
    "                try: \n",
    "                    with open('./gutenberg_clean/{}-0.txt'.format(book_id)) as f:\n",
    "                        text = f.read()\n",
    "                        texts[book_id] = text\n",
    "                except:\n",
    "                    missing_books.append(book_id)\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2512fef-7502-46bb-87df-b07c2a6f9f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = get_texts(text_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64c629f1-f67c-4e32-82fb-c2ca1cc4f69d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2316"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05864c0a-07fd-489f-9b29-2c22db660cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(missing_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9103d8ad-5de4-4f3d-994e-df875f07c357",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_books"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754fba54-2051-4de5-8437-835c53840514",
   "metadata": {},
   "source": [
    "Creating lists of missing books that can then be scraped"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f2817676-e5f1-4b18-870e-67e23374c6fd",
   "metadata": {},
   "source": [
    "missing_books_links = []\n",
    "for book_id in missing_books:\n",
    "    url = \"https://www.gutenberg.org/cache/epub/{}/pg{}.txt\".format(book_id, book_id)\n",
    "    missing_books_links.append(url)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d4d341b3-4e32-42f3-994f-6f246a308ab4",
   "metadata": {},
   "source": [
    "with open('missing_books_links.txt', 'w') as f:\n",
    "    for line in missing_books_links:\n",
    "        f.write(f\"{line}\\n\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0179bdb8-017b-4830-bcd2-8aa58f4a4795",
   "metadata": {},
   "source": [
    "missing_books_links = []\n",
    "for book_id in missing_books:\n",
    "    url = \"https://www.gutenberg.org/files/{}/{}-0.txt\".format(book_id, book_id)\n",
    "    missing_books_links.append(url)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b19c0940-dcee-4b02-b16d-25c8e0bb81c6",
   "metadata": {},
   "source": [
    "with open('missing_books_links_2.txt', 'w') as f:\n",
    "    for line in missing_books_links:\n",
    "        f.write(f\"{line}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04dffea-4fbd-4690-9365-2909b1b5d941",
   "metadata": {},
   "source": [
    "# Extract time-related words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f007718b-0302-4d41-903e-a1151a9c2e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the texts that mention a century\n",
    "count_century = 0\n",
    "texts_with_century = []\n",
    "for text in texts.values():\n",
    "    if \"century\" in text:\n",
    "        texts_with_century.append(text)\n",
    "        count_century += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b53a381-51dd-43ab-8179-bb0fd93a453f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "651"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_century"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4436ac45-64b2-40b9-98c3-5817e6b301a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ff9a5e5-d7d4-48bb-82a3-86dd12ab259d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pattern(doc):\n",
    "    matches = matcher(doc) \n",
    "    matches_text = []\n",
    "    for match_id, start, end in matches:\n",
    "        try: \n",
    "            string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
    "            span = doc[start:end]  # The matched span\n",
    "            #print(match_id, string_id, start, end, span.text)\n",
    "            if any(char.isdigit() for char in span.text): \n",
    "                #print(span.text)\n",
    "                matches_text.append(span.text)\n",
    "        except: \n",
    "            continue\n",
    "    return matches_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8b9b5ae1-7d55-46b6-a50a-829b82b88469",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern1 = [\n",
    "    {\"LENGTH\": {\">=\": 1}}, {\"LENGTH\": {\">=\": 1}}, {\"ENT_TYPE\": \"DATE\"}, {\"LENGTH\": {\">=\": 1}}, {\"LENGTH\": {\">=\": 1}}\n",
    "]\n",
    "matcher.add(\"Century\", [pattern1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d3f1bb1-b70c-418d-96b7-a37a69c90c61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n"
     ]
    }
   ],
   "source": [
    "# Find all the dete-related noun phrases\n",
    "matches_date_words = []\n",
    "count = 0\n",
    "for book_id, text in texts.items():  \n",
    "    # try: \n",
    "    doc = nlp(text[1 : 1000000]) # because of restriction of spacy\n",
    "    matches_text = find_pattern(doc)\n",
    "    matches_date_words.append({ \"book_id\": book_id, \"matches_text\": matches_text })\n",
    "    # except:\n",
    "    #     continue\n",
    "    count +=1 \n",
    "    if (count %100 == 0):\n",
    "        print(count)\n",
    "        with open('matches_date_words_{}.json'.format(count), 'w') as f:\n",
    "            json.dump(matches_date_words, f)\n",
    "        # with open('matches_date_words_{}.pickle'.format(count), 'wb') as handle:\n",
    "        #     pickle.dump(matches_date_words, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fc9cc561-7ee1-430b-b8ca-4b4556b149db",
   "metadata": {},
   "source": [
    "# save with pickle \n",
    "with open('matches_date_words.pickle', 'wb') as handle:\n",
    "    pickle.dump(matches_date_words, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "262374ca-5b1e-4554-b019-cf9a966307c6",
   "metadata": {},
   "source": [
    "# load with pickle\n",
    "with open('matches_date_words_2310.pickle', 'rb') as handle:\n",
    "    matches_date_words = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "efea7c72-ca78-44b7-8f28-77b681fb8a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save with json\n",
    "with open('matches_date_words.json', 'w') as f:\n",
    "    json.dump(matches_date_words, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3fca7b83-5223-45a4-b7ac-566bc8decb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load with json \n",
    "with open('matches_date_words.json', 'r') as f:\n",
    "    matches_date_words = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a67521a-28f8-47a0-a8d8-8ac6671767d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out to just titles with number over 2000 (or another number in them) \n",
    "def get_numbers_above(mystr, min_num=2000):\n",
    "    nums_greater_than_min_num = []\n",
    "    if any(char.isdigit() for char in mystr):\n",
    "        all_nums = (re.findall('\\d+', mystr))\n",
    "        for num in all_nums:\n",
    "            if int(num) >= min_num:\n",
    "                nums_greater_than_min_num.append(int(num))\n",
    "    if len(nums_greater_than_min_num) > 0:\n",
    "        return mystr, nums_greater_than_min_num\n",
    "    else:\n",
    "        return '', ''\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aab9edac-13f0-4e74-a6b1-eed6bb0a4ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello world 400 2000'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = 'hello world 400 2000'\n",
    "get_numbers_above(test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de3f3520-516d-4c1c-a5ae-204b4a92e219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'book_id': 35, 'matches_text': []}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches_date_words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ce04e59-5726-42ad-92ec-430f96d6f1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_date_words_with_over2000 = {}\n",
    "for book in matches_date_words:\n",
    "    matches_text = book['matches_text']\n",
    "    if len(matches_text):\n",
    "        valid_matches = []\n",
    "        valid_years = []\n",
    "        for entry in matches_text:\n",
    "            nums_greater_than_min_num = get_numbers_above(entry)[0]\n",
    "            if len(nums_greater_than_min_num) > 0:\n",
    "                valid_matches.append(nums_greater_than_min_num)\n",
    "                valid_years.extend(get_numbers_above(entry)[1])\n",
    "        if (len(valid_matches) > 0):\n",
    "            matches_date_words_with_over2000[str(book['book_id'])] = list(set(valid_years))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e858ab4f-6d85-43e2-87e4-36bc99177984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(matches_date_words_with_over2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1d93eefa-1608-498e-b13d-b1a04176af13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2354]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches_date_words_with_over2000['18520']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2cf8beb4-e587-4e26-b5e5-8cc8f60268ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a lookup of all the resulting titles \n",
    "df_filtered = df[df['Text#'].isin(list(matches_date_words_with_over2000.keys()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7f35049d-654b-46f2-98f4-abcb3fc04f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.to_csv('scifi_after_2000_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f881b1-5d07-47c6-b960-c996a88c0eab",
   "metadata": {},
   "source": [
    "Get longer surrounding text around the years for those books that contain years above 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "439b784c-f717-4b06-90d1-c82b2fda0fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all(a_str, sub):\n",
    "    start = 0\n",
    "    while True:\n",
    "        start = a_str.find(sub, start)\n",
    "        if start == -1: return\n",
    "        yield start\n",
    "        start += len(sub) # use start += 1 to find overlapping matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "235fb79e-27f2-41a8-bb21-456a3ddc7096",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1607\n",
      "18458\n",
      "18520\n",
      "19471\n",
      "19709\n",
      "19726\n",
      "20121\n",
      "20121\n",
      "20121\n",
      "20154\n",
      "20707\n",
      "20727\n",
      "20859\n",
      "20988\n",
      "21092\n",
      "21638\n",
      "21970\n",
      "22073\n",
      "23669\n",
      "24054\n",
      "24135\n",
      "24247\n",
      "24949\n",
      "25776\n",
      "26867\n",
      "26867\n",
      "26867\n",
      "26867\n",
      "26867\n",
      "26867\n",
      "27365\n",
      "27365\n",
      "27462\n",
      "27730\n",
      "29135\n",
      "29303\n",
      "29455\n",
      "29720\n",
      "29882\n",
      "30452\n",
      "30532\n",
      "30691\n",
      "30869\n",
      "31223\n",
      "31223\n",
      "31223\n",
      "31327\n",
      "31357\n",
      "32154\n",
      "32154\n",
      "32473\n",
      "32473\n",
      "32485\n",
      "32530\n",
      "32853\n",
      "32903\n",
      "32903\n",
      "33386\n",
      "33850\n",
      "38287\n",
      "39572\n",
      "49531\n",
      "49531\n",
      "49638\n",
      "50682\n",
      "51379\n",
      "51379\n",
      "51379\n",
      "51868\n",
      "53456\n",
      "53932\n",
      "54096\n",
      "54096\n",
      "54096\n",
      "54629\n",
      "58784\n",
      "59376\n",
      "59376\n",
      "59376\n",
      "59588\n",
      "59752\n",
      "59752\n",
      "59752\n",
      "59752\n",
      "59752\n",
      "59752\n",
      "59752\n",
      "60393\n",
      "60944\n",
      "61551\n",
      "61694\n",
      "61756\n",
      "63613\n",
      "63656\n",
      "63716\n",
      "63826\n",
      "64314\n",
      "64673\n",
      "64673\n",
      "64710\n",
      "65218\n",
      "65324\n",
      "65370\n",
      "65370\n",
      "65977\n",
      "66163\n",
      "66206\n",
      "66259\n",
      "66312\n",
      "67122\n",
      "68067\n",
      "68349\n",
      "69009\n",
      "69293\n",
      "69338\n",
      "69338\n",
      "69338\n",
      "69338\n",
      "69338\n",
      "69338\n",
      "69338\n",
      "69338\n",
      "69584\n",
      "69709\n",
      "69709\n"
     ]
    }
   ],
   "source": [
    "matches_date_words_2000 = []\n",
    "count = 0\n",
    "for book_id, text in texts.items(): \n",
    "    if str(book_id) in list(matches_date_words_with_over2000.keys()):\n",
    "        #print(book_id)\n",
    "        for year in matches_date_words_with_over2000[str(book_id)]:\n",
    "            year_locations = list(find_all(text, str(year)))\n",
    "            if (len(year_locations)> 1):\n",
    "                print(book_id)\n",
    "            samples = []\n",
    "            for loc in year_locations:\n",
    "                sample = text[loc-200:loc+200]\n",
    "                samples.append(sample)\n",
    "        matches_date_words_2000.append({ \"book_id\": book_id, \"matches_text\": samples })\n",
    "        count +=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0265f652-70e5-41dc-a54d-fe8311621ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'book_id': 19145,\n",
       " 'matches_text': ['in forces with a space man from Terra to outwit resurgent nonhuman\\nAliens. A sequel to _The Stars Are Ours!_ $2.75\\n\\n\\nTHE STARS ARE OURS!\\n\\n_by Andre Norton_\\n\\nTo escape the tyranny on Terra in the year 2500, a group of scientists\\nmake a last-minute getaway under fire and take off for another planet in\\nanother solar system. Their adventures make top-flight entertainment for\\nall science-fiction fans. ']}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches_date_words_2000[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dcc069-818f-443e-9e09-c2d8f91d740e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
